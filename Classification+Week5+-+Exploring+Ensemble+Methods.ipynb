{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Ensemble Methods\n",
    "\n",
    "In this homework we will explore the use of boosting. For this assignment, we will use the pre-implemented gradient boosted trees in Turi-Create. You will:\n",
    "\n",
    "Use SFrames to do some feature engineering.\n",
    "Train a boosted ensemble of decision-trees (gradient boosted trees) on the lending club dataset.\n",
    "Predict whether a loan will default along with prediction probabilities (on a validation set).\n",
    "Evaluate the trained model and compare it with a baseline.\n",
    "Find the most positive and negative loans using the learned model.\n",
    "Explore how the number of trees influences classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwang/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (19,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "loans = pd.read_csv('/Users/kevinwang/Documents/Coursera/Machine Learning - Classification/Week4/lending-club-data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "In this assignment, we will be using a subset of features (categorical and numeric). The features we will be using are described in the code comments below. If you are a finance geek, the LendingClub website has a lot more details about these features.\n",
    "\n",
    "The features we will be using are described in the code comments below. Extract these feature columns and target column from the dataset. We will only use these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies\n",
    "             'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', axis = 1)\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipping observations with missing values\n",
    "Recall from the lectures that one common approach to coping with missing values is to skip observations that contain missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans = loans[[target] + features].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(loans):\n",
    "    return pd.get_dummies(loans, dummy_na=True) \n",
    "    #return pd.get_dummies(loans, dummy_na=True)   # We don't need to identify Str variable, it will just transform 'object' var\n",
    "    # dummy_na=True => When emp_length has 'NA', we do create emp_length_NA column\n",
    "loans = one_hot(loans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37219, 48)\n",
      "(9284, 48)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('/Users/kevinwang/Documents/Coursera/Machine Learning - Classification/Week5/module-8-assignment-1-train-idx.json', 'r') as f: # Reads the list of most frequent words\n",
    "    train_idx = json.load(f)\n",
    "with open('/Users/kevinwang/Documents/Coursera/Machine Learning - Classification/Week5/module-8-assignment-1-validation-idx.json', 'r') as f1: # Reads the list of most frequent words\n",
    "    validation_idx = json.load(f1)\n",
    "\n",
    "train_data = loans.iloc[train_idx]\n",
    "validation_data = loans.iloc[validation_idx]\n",
    "print(train_data.shape)        #(37219, 25)\n",
    "print(validation_data.shape)   #(9284, 25)\n",
    "train_loans_prop = sum(train_data['safe_loans'] == 1)/len(train_data)   #0.5036137456675354   Means data is very balanced\n",
    "valid_loans_prop = sum(validation_data['safe_loans'] == 1)/len(validation_data)   #0.4967686342093925   Means data is very balanced\n",
    "y_train = train_data['safe_loans']\n",
    "x_train = train_data.drop('safe_loans', axis=1)\n",
    "\n",
    "y_valid = validation_data['safe_loans']\n",
    "x_valid = validation_data.drop('safe_loans', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosted tree classifier\n",
    "\n",
    "Gradient boosted trees are a powerful variant of boosting methods; they have been used to win many Kaggle competitions, and have been widely used in industry. We will explore the predictive power of multiple decision trees as opposed to a single decision tree.\n",
    "\n",
    "Additional reading: If you are interested in gradient boosted trees, here is some additional reading material:\n",
    "\n",
    "GraphLab Create user guide\n",
    "Advanced material on boosted trees\n",
    "We will now train models to predict safe_loans using the features above. In this section, we will experiment with training an ensemble of 5 trees.\n",
    "\n",
    "Now, let's use the built-in scikit learn gradient boosting classifier (sklearn.ensemble.GradientBoostingClassifier) to create a gradient boosted classifier on the training data. You will need to import sklearn, sklearn.ensemble, and numpy.\n",
    "\n",
    "You will have to first convert the SFrame into a numpy data matrix. See the API for more information. You will also have to extract the label column. Make sure to set \n",
    "\n",
    "max_depth=6 and \n",
    "\n",
    "n_estimators=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.665\n",
      "Accuracy score (validation): 0.661\n"
     ]
    }
   ],
   "source": [
    "model_5 = GradientBoostingClassifier(n_estimators=5, max_depth=6)\n",
    "model_5.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(model_5.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(model_5.score(x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "Just like we did in previous sections, let us consider a few positive and negative examples from the validation set. We will do the following:\n",
    "\n",
    "Predict whether or not a loan is likely to default.\n",
    "Predict the probability with which the loan is likely to default.\n",
    "\n",
    "First, let's grab 2 positive examples and 2 negative examples. In SFrame, that would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>sub_grade_num</th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>delinq_2yrs_zero</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_home_improvement</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>purpose_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.44</td>\n",
       "      <td>6.30496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.19</td>\n",
       "      <td>13.49520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13.97</td>\n",
       "      <td>2.96736</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.33</td>\n",
       "      <td>1.90524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    safe_loans  sub_grade_num  short_emp  emp_length_num    dti  \\\n",
       "22           1            0.2          0               3  29.44   \n",
       "26           1            0.6          1               1  12.19   \n",
       "24          -1            0.4          0               3  13.97   \n",
       "41          -1            1.0          0              11  16.33   \n",
       "\n",
       "    payment_inc_ratio  delinq_2yrs  delinq_2yrs_zero  inq_last_6mths  \\\n",
       "22            6.30496          0.0               1.0             0.0   \n",
       "26           13.49520          0.0               1.0             0.0   \n",
       "24            2.96736          3.0               0.0             0.0   \n",
       "41            1.90524          0.0               1.0             0.0   \n",
       "\n",
       "    last_delinq_none  ...  purpose_home_improvement  purpose_house  \\\n",
       "22                 1  ...                         0              0   \n",
       "26                 1  ...                         0              0   \n",
       "24                 0  ...                         0              0   \n",
       "41                 1  ...                         0              0   \n",
       "\n",
       "    purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  \\\n",
       "22                       0                0               0              0   \n",
       "26                       0                0               0              0   \n",
       "24                       0                0               0              1   \n",
       "41                       0                0               0              0   \n",
       "\n",
       "    purpose_small_business  purpose_vacation  purpose_wedding  purpose_nan  \n",
       "22                       0                 0                0            0  \n",
       "26                       0                 0                0            0  \n",
       "24                       0                 0                0            0  \n",
       "41                       0                 0                0            0  \n",
       "\n",
       "[4 rows x 48 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "sample_validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row in the sample_validation_data, write code to make model_5 predict whether or not the loan is classified as a safe loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.predict(sample_validation_data.drop('safe_loans',1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz question: What percentage of the predictions on sample_validation_data did model_5 get correct?\n",
    "\n",
    "Answer: 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Probabilities\n",
    "\n",
    "For each row in the sample_validation_data, what is the probability (according model_5) of a loan being classified as safe? (Hint: if you are using scikit-learn, you can use the .predict_proba() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41642331 0.58357669]\n",
      " [0.46949689 0.53050311]\n",
      " [0.53807792 0.46192208]\n",
      " [0.39591639 0.60408361]]\n",
      "[0.41642331 0.46949689 0.53807792 0.39591639]\n",
      "[0.58357669 0.53050311 0.46192208 0.60408361]\n"
     ]
    }
   ],
   "source": [
    "sample_prob = model_5.predict_proba(sample_validation_data.drop('safe_loans',1))\n",
    "print(sample_prob)\n",
    "risk_prob = sample_prob[:,0]\n",
    "safe_prob = sample_prob[:,1]\n",
    "print(risk_prob)\n",
    "print(safe_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz Question: Which loan has the highest probability of being classified as a safe loan?\n",
    "\n",
    "Answer: 4th. \n",
    "\n",
    "Quiz Question: According to model_5, which loan is the least likely to be a safe loan?\n",
    "\n",
    "Answer: 3th.\n",
    "    \n",
    "Checkpoint: Can you verify that for all the predictions with probability >= 0.5, the model predicted the label +1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model on the validation data\n",
    "\n",
    "Recall that the accuracy is defined as follows:\n",
    "\n",
    "accuracy=# correctly classified data points / # total data points\n",
    "\n",
    "Evaluate the accuracy of the model_5 on the validation_data. (Hint: if you are using scikit-learn, you can use the .score() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.665\n",
      "Accuracy score (validation): 0.661\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score (training): {0:.3f}\".format(model_5.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(model_5.score(x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of false positives made by the model on the validation_data.\n",
    "\n",
    "Calculate the number of false negatives made by the model on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3020 1652]\n",
      " [1491 3121]]\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.67      0.65      0.66      4672\n",
      "          1       0.65      0.68      0.67      4612\n",
      "\n",
      "avg / total       0.66      0.66      0.66      9284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "predictions = model_5.predict(x_valid)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, model_5.predict(x_valid)))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_valid, model_5.predict(x_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1652\n",
      "1491\n",
      "3121\n"
     ]
    }
   ],
   "source": [
    "False_Positive = sum(model_5.predict(x_valid) > y_valid)\n",
    "print(False_Positive)\n",
    "\n",
    "False_Negative = sum(model_5.predict(x_valid) < y_valid)\n",
    "print(False_Negative)\n",
    "\n",
    "True_Positive = sum((model_5.predict(x_valid) == y_valid) & (y_valid==1))\n",
    "print(True_Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz question: What is the number of false positives on the validation_data?\n",
    "\n",
    "Answer: 1652"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with decision trees\n",
    "\n",
    "In the earlier assignment, we saw that the prediction accuracy of the decision trees was around 0.64. In this assignment, we saw that model_5 has an accuracy of approximately 0.67.\n",
    "\n",
    "Here, we quantify the benefit of the extra 3% increase in accuracy of model_5 in comparison with a single decision tree from the original decision tree assignment.\n",
    "\n",
    "As we explored in the earlier assignment, we calculated the cost of the mistakes made by the model. We again consider the same costs as follows:\n",
    "\n",
    "False negatives: Assume a cost of $10,000 per false negative.\n",
    "\n",
    "False positives: Assume a cost of $20,000 per false positive.\n",
    "\n",
    "Assume that the number of false positives and false negatives for the learned decision tree was\n",
    "\n",
    "False negatives: 1936\n",
    "False positives: 1503\n",
    "\n",
    "Using the costs defined above and the number of false positives and false negatives for the decision tree, we can calculate the total cost of the mistakes made by the decision tree model as follows:\n",
    "\n",
    "cost = $10,000 * 1936  + $20,000 * 1503 = $49,420,000\n",
    "\n",
    "The total cost of the mistakes of the model is $49.42M. That is a lot of money!.\n",
    "\n",
    "Calculate the cost of mistakes made by model_5 on the validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47950000\n"
     ]
    }
   ],
   "source": [
    "False_Neg_Cost = 10000\n",
    "False_Pos_Cost = 20000\n",
    "print(False_Neg_Cost * False_Negative + False_Pos_Cost * False_Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz: Using the same costs of the false positives and false negatives, what is the cost of the mistakes made by the boosted tree model (model_5) as evaluated on the validation_set?\n",
    "\n",
    "Answer: 47950000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most positive & negative loans.\n",
    "In this section, we will find the loans that are most likely to be predicted safe. We can do this in a few steps:\n",
    "\n",
    "Step 1: Use the model_5 (the model with 5 trees) and make probability predictions for all the loans in validation_data.\n",
    "\n",
    "Step 2: Similar to what we did in the very first assignment, add the probability predictions as a column called predictions into validation_data.\n",
    "\n",
    "Step 3: Sort the data (in descreasing order) by the probability predictions.\n",
    "\n",
    "\n",
    "Start here with Step 1 & Step 2. Make predictions using model_5 for all examples in the validation_data.\n",
    "\n",
    "Checkpoint: For each row, the probabilities should be a number in the range [0, 1].\n",
    "\n",
    "Now, we are ready to go to Step 3. You can now use the prediction column to sort the loans in validation_data (in descending order) by prediction probability. Find the top 5 loans with the highest probability of being predicted as a safe loan.\n",
    "\n",
    "Repeat this exercise to find the 5 loans (in the validation_data) with the lowest probability of being predicted as a safe loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6199729e42f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Risk_prob'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Safe_prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#nd_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcombine_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(valid_prob, columns = ['Risk_prob','Safe_prob'])\n",
    "valid_df = pd.DataFrame(validation_data)\n",
    "type(np.hstack((df, y_valid_df)))   #nd_array\n",
    "combine_df = pd.DataFrame(np.hstack((df, y_valid_df)))\n",
    "print(combine_df.columns)\n",
    "combine_df.rename(columns = {1:'predictions', 2: 'actual'}, inplace = True) \n",
    "print(combine_df)\n",
    "combine_df = combine_df.drop(0, axis = 1)\n",
    "print(combine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       predictions  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F\n",
      "8021      0.673059        1        0        0        0        0        0\n",
      "92079     0.661468        1        0        0        0        0        0\n",
      "68973     0.661468        1        0        0        0        0        0\n",
      "19865     0.661468        1        0        0        0        0        0\n",
      "19954     0.661468        1        0        0        0        0        0\n",
      "        predictions  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F\n",
      "101746     0.315973        0        0        0        1        0        0\n",
      "114781     0.315973        0        0        0        1        0        0\n",
      "27502      0.312806        0        0        1        0        0        0\n",
      "58794      0.307334        0        0        1        0        0        0\n",
      "84508      0.307334        0        0        1        0        0        0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(valid_prob, columns = ['Risk_prob','Safe_prob'], index = list(validation_data.index))\n",
    "df = df.drop('Risk_prob', axis = 1)\n",
    "df = df.rename({'Safe_prob': 'predictions'}, axis=1)\n",
    "valid_df = pd.DataFrame(validation_data)\n",
    "combine_df = pd.concat([df, valid_df], axis=1, sort=False)\n",
    "combine_df.sort_values(by=['predictions'], inplace=True, ascending=False)\n",
    "safest5 = combine_df.head(5)[['predictions', 'grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F']]\n",
    "riskest5 = combine_df.tail(5)[['predictions', 'grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F']]\n",
    "print(safest5)\n",
    "print(riskest5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz question: What grades are the top 5 loans?\n",
    "\n",
    "Answer: grade_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of adding more trees\n",
    "\n",
    "In this assignment, we will train 5 different ensemble classifiers in the form of gradient boosted trees.\n",
    "\n",
    "Train models with 10, 50, 100, 200, and 500 trees. Use the n_estimators parameter to control the number of trees. Remember to keep max_depth = 6.\n",
    "\n",
    "Call these models model_10, model_50, model_100, model_200, and model_500, respectively. This may take a few minutes to run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score (training): 0.67108\n",
      "Accuracy score (validation): 0.66545\n",
      "Accuracy score (training): 0.71729\n",
      "Accuracy score (validation): 0.68440\n",
      "Accuracy score (training): 0.74637\n",
      "Accuracy score (validation): 0.68914\n",
      "Accuracy score (training): 0.78729\n",
      "Accuracy score (validation): 0.68613\n",
      "Accuracy score (training): 0.86367\n",
      "Accuracy score (validation): 0.68979\n"
     ]
    }
   ],
   "source": [
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6)\n",
    "model_10.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.5f}\".format(model_10.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.5f}\".format(model_10.score(x_valid, y_valid)))\n",
    "\n",
    "model_50 = GradientBoostingClassifier(n_estimators=50, max_depth=6)\n",
    "model_50.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.5f}\".format(model_50.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.5f}\".format(model_50.score(x_valid, y_valid)))\n",
    "\n",
    "model_100 = GradientBoostingClassifier(n_estimators=100, max_depth=6)\n",
    "model_100.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.5f}\".format(model_100.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.5f}\".format(model_100.score(x_valid, y_valid)))\n",
    "\n",
    "model_200 = GradientBoostingClassifier(n_estimators=200, max_depth=6)\n",
    "model_200.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.5f}\".format(model_200.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.5f}\".format(model_200.score(x_valid, y_valid)))\n",
    "\n",
    "model_500 = GradientBoostingClassifier(n_estimators=500, max_depth=6)\n",
    "model_500.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy score (training): {0:.5f}\".format(model_500.score(x_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.5f}\".format(model_500.score(x_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare accuracy on entire validation set\n",
    "Now we will compare the predicitve accuracy of our models on the validation set.\n",
    "\n",
    "Evaluate the accuracy of the 10, 50, 100, 200, and 500 tree models on the validation_data.\n",
    "\n",
    "Quiz Question: Which model has the best accuracy on the validation_data?\n",
    "\n",
    "Answer: not 200 not Model_500\n",
    "\n",
    "Quiz Question: Is it always true that the model with the most trees will perform best on test data?\n",
    "\n",
    "Answer: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the classification errors (on the train_data and validation_data) versus the number of trees, we will need lists of all the errors.\n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "Step 1: Calculate the classification error for each model on the training data (train_data).\n",
    "Step 2: Store the training errors into a list (called training_errors) that looks like this: [train_err_10, train_err_50, ..., train_err_500]\n",
    "Step 3: Calculate the classification error of each model on the validation data (validation_data).\n",
    "Step 4: Store the validation classification error into a list (called validation_errors) that looks like this:[validation_err_10, validation_err_50, ..., validation_err_500]\n",
    "Once that has been completed, we will give code that should be able to evaluate correctly and generate the plot.\n",
    "\n",
    "Let us start with Step 1. Write code to compute the classification error on the train_data for models model_10, model_50, model_100, model_200, and model_500.\n",
    "\n",
    "Now, let us run Step 2. Save the training errors into a list called training_errors.\n",
    "\n",
    "Now, onto Step 3. Write code to compute the classification error on the validation_data for models model_10, model_50, model_100, model_200, and model_500.\n",
    "\n",
    "Now, let us run Step 4. Save the training errors into a list called validation_errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [model_10, model_50, model_100, model_200, model_500]\n",
    "training_errors = []\n",
    "validation_errors = []\n",
    "for i in range(5):\n",
    "    training_errors.append(1-models[i].score(x_train, y_train))\n",
    "    validation_errors.append(1-models[i].score(x_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAELCAYAAAAP/iu7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([10, 50, 100, 200, 500], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100, 200, 500], validation_errors, linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz: Does the training error reduce as the number of trees increases?\n",
    "    \n",
    "Answer: Yes\n",
    "    \n",
    "Quiz: Is it always true that the test/validation error will reduce as the number of trees increases?\n",
    "\n",
    "Answer: No"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
